#!/usr/bin/env python3
"""
High-Precision Trajectory Prediction System
Algorithm: Constant Turn Rate and Acceleration (CTRA) with Gaussian Smoothing
Status: Production Grade
"""

import numpy as np
import cv2
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import argparse
from collections import defaultdict
from scipy.ndimage import gaussian_filter1d  # Requires: pip install scipy

# Import existing modules
try:
    from interactive_analytics import VehicleAnalyzer, VehicleTracker
except ImportError:
    # Fallback for standalone testing if modules aren't found
    print("Warning: 'interactive_analytics' not found. Using mocks for testing.")
    class VehicleAnalyzer:
        def __init__(self, **kwargs): pass
        def load_model(self): pass
        def analyze_frame(self, frame, roi): return {'roi_vehicles': []}
    class VehicleTracker:
        def __init__(self, **kwargs): pass
        def update(self, dets): return {}

class PhysicsTrajectoryPredictor:
    """
    Implements CTRA (Constant Turn Rate and Acceleration) model
    for organic, smooth vehicle path prediction.
    """
    
    def __init__(
        self,
        video_path: str,
        confidence_threshold: float = 0.3,
        history_window: int = 20,   # Frames to look back
        prediction_horizon: int = 60 # Frames to predict forward
    ):
        self.video_path = video_path
        self.history_window = history_window
        self.prediction_horizon = prediction_horizon
        
        # Initialize Analytics
        self.analyzer = VehicleAnalyzer(
            model_conf=confidence_threshold,
            use_sahi=True,
            sahi_slice_size=640
        )
        self.analyzer.load_model()
        self.tracker = VehicleTracker(min_iou=0.3, max_age=30)
        
        # Data Structures
        self.trajectories: Dict[int, List[np.ndarray]] = defaultdict(list)
        # Predictions store: (Center Path, Left Boundary, Right Boundary, Velocity)
        self.predictions: Dict[int, Tuple[np.ndarray, np.ndarray, np.ndarray, float]] = {}
        
        # Frame Metadata
        self.frame_width = 0
        self.frame_height = 0
        self.fps = 30.0

    def analyze(self, start_frame: int = 0, duration_frames: int = 300):
        cap = cv2.VideoCapture(self.video_path)
        if not cap.isOpened():
            raise ValueError(f"Could not open {self.video_path}")

        # Video Metadata
        self.fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
        self.frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        end_frame = min(start_frame + duration_frames, total_frames)
        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
        
        print(f"\n--- INITIATING ADVANCED PHYSICS TRACKING ---")
        print(f"Algorithm: CTRA (Constant Turn Rate & Acceleration)")
        print(f"Smoothing: Gaussian Kernel (sigma=2.0)")
        print(f"Processing: Frames {start_frame} -> {end_frame}")
        
        current_frame = start_frame
        
        while current_frame < end_frame:
            ret, frame = cap.read()
            if not ret: break
            
            # 1. Detection & Tracking
            # Using full frame for maximum context
            roi = [(0, 0), (self.frame_width, 0), 
                   (self.frame_width, self.frame_height), (0, self.frame_height)]
            
            analysis = self.analyzer.analyze_frame(frame, roi)
            tracked_objects = self.tracker.update(analysis['roi_vehicles'])
            
            # 2. Update Trajectories
            for v_id, data in tracked_objects.items():
                bbox = data['bbox']
                # Compute centroid
                cx = (bbox[0] + bbox[2]) / 2.0
                cy = (bbox[1] + bbox[3]) / 2.0
                self.trajectories[v_id].append(np.array([cx, cy]))
            
            if current_frame % 20 == 0:
                print(f"Processing frame {current_frame}/{end_frame} | Active tracks: {len(tracked_objects)}")
            
            current_frame += 1
            
        cap.release()
        self._compute_physics_predictions()

    def _get_smooth_derivatives(self, positions: np.ndarray) -> Tuple[np.ndarray, np.ndarray, float]:
        """
        Applies Gaussian Smoothing to trajectory and calculates velocity/heading.
        Returns: (Smoothed Pos, Velocity Vector, Speed Scalar)
        """
        # We need at least 5 points for a reliable gaussian filter
        if len(positions) < 5:
            return positions, np.zeros(2), 0.0

        # Separate X and Y
        x = positions[:, 0]
        y = positions[:, 1]

        # 1. Gaussian Smoothing (Sigma=2 handles jitter well)
        x_smooth = gaussian_filter1d(x, sigma=2.0)
        y_smooth = gaussian_filter1d(y, sigma=2.0)
        smoothed_pos = np.column_stack((x_smooth, y_smooth))

        # 2. Calculate Velocity (First Derivative)
        # Using central difference for better accuracy on the tail
        dx = np.gradient(x_smooth)
        dy = np.gradient(y_smooth)
        
        # Velocity vector at the last frame
        velocity_vector = np.array([dx[-1], dy[-1]])
        speed = np.linalg.norm(velocity_vector)
        
        return smoothed_pos, velocity_vector, speed

    def _compute_physics_predictions(self):
        """
        The Core CTRA Algorithm.
        Integrates state [x, y, v, yaw, yaw_rate, a] forward in time.
        """
        print(f"\nComputing physics models for {len(self.trajectories)} trajectories...")
        
        dt = 1.0  # Time step (normalized to 1 frame)

        for v_id, raw_path in self.trajectories.items():
            path_arr = np.array(raw_path)
            
            # Filter out short/static noise
            if len(path_arr) < self.history_window // 2:
                continue

            # 1. Get Smoothed State
            smooth_path, vel_vec, speed = self._get_smooth_derivatives(path_arr)
            
            # Skip if vehicle is effectively stationary
            if speed < 0.5:
                continue

            # 2. Calculate Kinematic State
            # Current Position
            x, y = smooth_path[-1]
            
            # Yaw (Heading)
            yaw = np.arctan2(vel_vec[1], vel_vec[0])
            
            # Yaw Rate (Change in heading over last few frames)
            # We look back 5 frames to estimate the turn rate
            lookback = 5
            if len(smooth_path) > lookback:
                prev_vel = smooth_path[-1] - smooth_path[-2]
                prev_yaw = np.arctan2(prev_vel[1], prev_vel[0])
                
                old_vel = smooth_path[-lookback] - smooth_path[-lookback-1]
                old_yaw = np.arctan2(old_vel[1], old_vel[0])
                
                # Handle angle wrapping (-pi to pi)
                diff = prev_yaw - old_yaw
                while diff <= -np.pi: diff += 2*np.pi
                while diff > np.pi: diff -= 2*np.pi
                
                yaw_rate = diff / lookback
            else:
                yaw_rate = 0.0

            # Acceleration (Change in speed)
            acc = 0.0 # Simplify to 0 for stability unless history is very long

            # 3. Integration Loop (CTRA Model)
            future_path = []
            
            # We predict two boundary paths (left/right limits) for visualization
            # based on "uncertainty growth"
            
            curr_x, curr_y = x, y
            curr_yaw = yaw
            curr_speed = speed
            
            # Dynamic horizon based on speed (faster cars need longer lookahead)
            dynamic_horizon = min(self.prediction_horizon, int(self.prediction_horizon * (curr_speed / 2.0) + 20))
            dynamic_horizon = min(dynamic_horizon, 120) # Cap at 120 frames

            for t in range(dynamic_horizon):
                # Update Yaw
                curr_yaw += yaw_rate
                # Dampen yaw rate (drivers straighten out turns eventually)
                yaw_rate *= 0.95 
                
                # Update Speed
                curr_speed += acc
                if curr_speed < 0: curr_speed = 0
                
                # Update Position
                curr_x += curr_speed * np.cos(curr_yaw)
                curr_y += curr_speed * np.sin(curr_yaw)
                
                # Boundary check
                if not (0 <= curr_x < self.frame_width and 0 <= curr_y < self.frame_height):
                    break
                
                future_path.append([curr_x, curr_y])

            if not future_path:
                continue
                
            future_path = np.array(future_path)
            
            # 4. Generate Uncertainty Cone
            # We create a "Left" and "Right" boundary to draw a transparent filled shape
            left_bound = []
            right_bound = []
            
            for i, pt in enumerate(future_path):
                # Width of uncertainty grows over time
                width = 5 + (i * 0.5 * curr_speed)
                
                # Normal vector to path
                if i > 0:
                    dx = pt[0] - future_path[i-1][0]
                    dy = pt[1] - future_path[i-1][1]
                    heading = np.arctan2(dy, dx)
                else:
                    heading = yaw
                
                norm_angle = heading + np.pi/2
                
                lx = pt[0] + width * np.cos(norm_angle)
                ly = pt[1] + width * np.sin(norm_angle)
                rx = pt[0] - width * np.cos(norm_angle)
                ry = pt[1] - width * np.sin(norm_angle)
                
                left_bound.append([lx, ly])
                right_bound.append([rx, ry])

            self.predictions[v_id] = (
                future_path, 
                np.array(left_bound), 
                np.array(right_bound), 
                speed
            )
            
        print(f"Generated smooth physics paths for {len(self.predictions)} vehicles.")

    def visualize(self, output_dir: str = "output/enhanced_predictions"):
        out_path = Path(output_dir)
        out_path.mkdir(parents=True, exist_ok=True)
        
        # Get background
        cap = cv2.VideoCapture(self.video_path)
        cap.set(cv2.CAP_PROP_POS_FRAMES, int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) // 2)
        ret, bg = cap.read()
        cap.release()
        
        if not ret: return
        
        # Create a separate layer for alpha blending (transparency)
        overlay = bg.copy()
        
        print("\nRendering high-fidelity visualization...")
        
        sorted_vehs = sorted(self.predictions.items(), key=lambda x: x[1][3], reverse=True)
        
        for v_id, (center_path, left, right, speed) in sorted_vehs:
            # Color generation (Deterministic but distinct)
            np.random.seed(v_id)
            color_base = np.random.randint(50, 255, 3).tolist()
            color = tuple(int(c) for c in color_base) # BGR
            
            # 1. Draw Historical Trail (Fading)
            history = np.array(self.trajectories[v_id])
            if len(history) > 1:
                # Smooth the history for display too
                hist_smooth = gaussian_filter1d(history, sigma=1.5, axis=0).astype(np.int32)
                cv2.polylines(bg, [hist_smooth], False, color, 2, cv2.LINE_AA)
            
            # 2. Draw Uncertainty Cone (Filled Polygon)
            if len(left) > 1 and len(right) > 1:
                # Create polygon from left path forward and right path backward
                poly_pts = np.vstack((left, right[::-1])).astype(np.int32)
                
                # Draw filled cone on overlay
                cv2.fillPoly(overlay, [poly_pts], color)
            
            # 3. Draw Center Prediction Line (Dashed effect simulation)
            center_pts = center_path.astype(np.int32)
            cv2.polylines(bg, [center_pts], False, (255, 255, 255), 2, cv2.LINE_AA)
            
            # 4. Draw End Marker
            if len(center_pts) > 0:
                cv2.circle(bg, tuple(center_pts[-1]), 4, color, -1)
                cv2.circle(bg, tuple(center_pts[-1]), 6, (255,255,255), 1)

        # Blend overlay (predictions) with background
        alpha = 0.4 # Transparency of cones
        cv2.addWeighted(overlay, alpha, bg, 1 - alpha, 0, bg)
        
        # Add Legend
        cv2.putText(bg, f"Physics Model: CTRA (Smoothed)", (20, 40), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)
        cv2.putText(bg, f"Vehicles Tracked: {len(self.predictions)}", (20, 80), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (200,200,200), 1)

        outfile = out_path / "trajectory_prediction_physics.png"
        cv2.imwrite(str(outfile), bg)
        print(f"\nâœ“ Saved enhanced visualization to: {outfile}")

def main():
    parser = argparse.ArgumentParser(description="Physics-based Trajectory Prediction")
    parser.add_argument("video", help="Input video file path")
    parser.add_argument("--start", type=int, default=0, help="Start frame")
    parser.add_argument("--frames", type=int, default=300, help="Duration")
    
    args = parser.parse_args()
    
    predictor = PhysicsTrajectoryPredictor(args.video)
    predictor.analyze(start_frame=args.start, duration_frames=args.frames)
    predictor.visualize()

if __name__ == "__main__":
    main()